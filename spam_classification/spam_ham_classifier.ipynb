{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7c7366",
   "metadata": {},
   "source": [
    "## **Spam and Ham Email Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368eb1a",
   "metadata": {},
   "source": [
    "*Group: Gregg Maloy, Jacob Silver, and Justin Williams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e919afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08930d",
   "metadata": {},
   "source": [
    "First, we'll read in a \"spam and ham\" dataset we found on kaggle. The data consists of emails from Enron, the energy company that collapsed amid a massive fraud scandal in the early 2000s. As we'll see when we explore the data further, each of email is labeled as either \"spam\" or \"ham\" (aka not spam). That means that we can both train our model on known label values, and later test its accuracy on a subset of the data we set aside.\n",
    "\n",
    "Let's pull in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0253db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "881e27ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b5d3b",
   "metadata": {},
   "source": [
    "As we can see, in addition to the ham/spam label and raw email text, the data contains a column called **label_num**, which simply assigns a value of 0 to ham emails and 1 to spam. This saves us the trouble of mapping the data this way ourselves, which is a necessary step for modeling; such algorithms expect numerical rather than categorical data.\n",
    "\n",
    "There is also a column called **Unnamed: 0** which appears wholly unnecessary, and is perhaps a holdover index from a previous, differently-shuffled iteration of the data. Let's remove it so our data is as clean as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "56d760cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = \"Unnamed: 0\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84bf5f",
   "metadata": {},
   "source": [
    "It appears that all of the raw emails in the **text** column begin with the word \"Subject\". It's useful to know what words are in the email's subject line, but the word \"Subject\" itself is unnecessary and may muddy our text. Once we confirm that all of the emails begin this way, we can remove it from all of them.\n",
    "\n",
    "We have a choice whether to consider the subject line differently than other text. Should it be treated as its own set of features? If it contains words taken from the text body, should we remove them to avoid duplication?\n",
    "\n",
    "For the sake of simplicity and staying true to a \"bag of words\" approach, we elected to keep the words of the subject line, but treat them as part of our broader text. If the words in the subject line are repeated in the body, so be it; it may make sense for them to be weighted as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "11baa8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject:     5171\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the first 9 characters of each raw text are identical\n",
    "df['text'].apply(lambda x: x[:9]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c212c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove that text from all\n",
    "df['text'] = df['text'].apply(lambda x: x[9:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d838ac9",
   "metadata": {},
   "source": [
    "At a glance the text all appears to be lower-case, but let's confirm just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a89f7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5153\n",
       "False      18\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: x.islower()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fc926",
   "metadata": {},
   "source": [
    "Almost, but not quite; let's make all the text lower for the sake of consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2e80fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0560fd6e",
   "metadata": {},
   "source": [
    "In order to build a model based on this text, we need them to be represented numerically. To do this, we need to break each text into its constituent parts (in this case, words), then represent each text as a collection of counts for each word. All words occurring in the entire corpus are thus treated as variables (or \"features\") in the model, whose weights are determined by the number of occurrences in that particular text. For the vast majority of these words, the weight in any given text will be 0--but we still need them to be laid out as consistent vectors. \n",
    "\n",
    "This process is called **Vectorization**, and thankfully, python--specifically, the sklearn package--contains useful functionality for the purpose. First, we can instantiate our Vectorizer. Here, we include the argument 'english' for the optional stop_words parameter. This will automatically exclude English-language stop-words (highly common words like \"a\" and \"the\") which could clutter our vectors with no value to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6a917618",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4961ab3",
   "metadata": {},
   "source": [
    "Next, by fitting our vectorizer to our corpus, we are asking it to develop the \"vocabulary\", or unique set of words, for our emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "32d8a887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f734a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50140"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb278f6",
   "metadata": {},
   "source": [
    "The command *vect.get_feature_names_out()* returns an array containing every word across all emails. That means our model will have just over 50,000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d64c9",
   "metadata": {},
   "source": [
    "Our next step is to create a new DataFrame representing our email data as vectors. This will facilitate the later work of splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "03827b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While this is not necessary, we appended our label_num column (which is our dependent variable) to all of our\n",
    "#independent feature columns, which we derive from a 2-dimensional vector array.\n",
    "df1 = pd.concat([df[['label_num']],\n",
    "                 pd.DataFrame(vect.transform(df['text']).toarray(), columns=vect.get_feature_names_out())],\n",
    "                axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c608fb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000000000002858</th>\n",
       "      <th>000000000049773</th>\n",
       "      <th>000080</th>\n",
       "      <th>000099</th>\n",
       "      <th>0001</th>\n",
       "      <th>...</th>\n",
       "      <th>zynve</th>\n",
       "      <th>zyqtaqlt</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zyyqywp</th>\n",
       "      <th>zzezrjok</th>\n",
       "      <th>zzn</th>\n",
       "      <th>zzo</th>\n",
       "      <th>zzocb</th>\n",
       "      <th>zzso</th>\n",
       "      <th>zzsyt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_num  00  000  0000  000000  000000000002858  000000000049773  000080  \\\n",
       "0          0   1    0     0       0                0                0       0   \n",
       "1          0   0    0     0       0                0                0       0   \n",
       "2          0   0    0     0       0                0                0       0   \n",
       "3          1   0    0     0       0                0                0       0   \n",
       "4          0   0    0     0       0                0                0       0   \n",
       "\n",
       "   000099  0001  ...  zynve  zyqtaqlt  zyrtec  zyyqywp  zzezrjok  zzn  zzo  \\\n",
       "0       0     0  ...      0         0       0        0         0    0    0   \n",
       "1       0     0  ...      0         0       0        0         0    0    0   \n",
       "2       0     0  ...      0         0       0        0         0    0    0   \n",
       "3       0     0  ...      0         0       0        0         0    0    0   \n",
       "4       0     0  ...      0         0       0        0         0    0    0   \n",
       "\n",
       "   zzocb  zzso  zzsyt  \n",
       "0      0     0      0  \n",
       "1      0     0      0  \n",
       "2      0     0      0  \n",
       "3      0     0      0  \n",
       "4      0     0      0  \n",
       "\n",
       "[5 rows x 50141 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b463c7",
   "metadata": {},
   "source": [
    "Now that we have a DataFrame with vectorized data, we can split it into training and testing sets using the *train_test_split* functionality in the sklearn package. This function takes in a DataFrame of independent variable features, an array of the dependent variable, and a ratio for breaking up the data.\n",
    "\n",
    "For the independent *x* DataFrame, we input df1.iloc[:,1:], representing all feature columns in df1. For the dependent *y* array, we use only the label_num column. Finally, we use 0.20 as our test size, relying on an industry standard 80/20 split between training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3c72c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df1.iloc[:,1:],df1['label_num'],test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4cdc6",
   "metadata": {},
   "source": [
    "It is now time to build our model. A Multinomial Naive Bayes classifier is commonly used for cases like this, and should be suitable. We can build such a model using sklearn's MultinomialNB functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ad624426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate Multinomial Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "#fit the model to our training data\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac60231",
   "metadata": {},
   "source": [
    "Now that we have a model trained on 80% of our emails, we can test it on the remaining 20% reserved for that purpose, using the *predict* method for MultinomialNB classifiers. This returns an array of 0s and 1s, which represent the models prediction for whether each email is ham (0) or spam (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fc03c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2dfcfe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e937fa4",
   "metadata": {},
   "source": [
    "Finally, we can test the accuracy of our model using sklearn's *classification_report* function. This produces a report that compares our predicted results against the true ham/spam values we know from our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a696a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       731\n",
      "           1       0.95      0.98      0.97       304\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d808e",
   "metadata": {},
   "source": [
    "Per this report, our model is quite effective! Let's break down some of the findings:\n",
    "\n",
    "- The model classified ham with 99% **precision** and spam with 95% precision. That means that of all the emails the model guessed were ham, 99% really were, and of the emails it classified as spam, 95% were indeed spam.\n",
    "- For both ham and spam, the model scored 98% on **recall**. That means that of all the actual spam emails in the test data, the model identified 98% of them. Likewise for ham.\n",
    "- F1-Score is, per the classificion_report documentation, a \"harmonic mean of the precision and recall.\" The best possible F1 score is 1, so scores of .99 and .97 are quite high!\n",
    "- Accuracy is simply the total number of correct predictions over the total number of predictions. Thus, it can be said that our model is 98% accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
